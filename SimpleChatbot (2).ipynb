{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObemhHTbVxUNiesMbzjwzQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9xn9yfcgpoM2"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**Setup** **Environment**"],"metadata":{"id":"DH_nG1oZrv3W"}},{"cell_type":"code","source":["!pip install gemini"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPHzispbr25q","executionInfo":{"status":"ok","timestamp":1720368295272,"user_tz":-330,"elapsed":61161,"user":{"displayName":"sanjivani sharma","userId":"08343980027590609131"}},"outputId":"dbef3b32-31de-4065-91f0-2247f0cd7055"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gemini\n","  Downloading gemini-0.30.2.tar.gz (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from gemini) (1.25.2)\n","Collecting inheritance>=0.1.3 (from gemini)\n","  Downloading inheritance-0.1.5.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting geneimpacts>=0.1.3 (from gemini)\n","  Downloading geneimpacts-0.3.7.tar.gz (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cython>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from gemini) (3.0.10)\n","Requirement already satisfied: sqlalchemy>=1 in /usr/local/lib/python3.10/dist-packages (from gemini) (2.0.31)\n","Collecting pysam>=0.6 (from gemini)\n","  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cyvcf2>=0.7.2 (from gemini)\n","  Downloading cyvcf2-0.31.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from gemini) (6.0.1)\n","Collecting pybedtools>=0.6.2 (from gemini)\n","  Downloading pybedtools-0.10.0.tar.gz (12.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jinja2>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from gemini) (3.1.4)\n","Requirement already satisfied: networkx>=1.10 in /usr/local/lib/python3.10/dist-packages (from gemini) (3.3)\n","Collecting bottle>=0.11.6 (from gemini)\n","  Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipyparallel>=4.0 in /usr/local/lib/python3.10/dist-packages (from gemini) (8.8.0)\n","Collecting ipython-cluster-helper>=0.5.1 (from gemini)\n","  Downloading ipython-cluster-helper-0.6.4.tar.gz (22 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bx-python>=0.7.1 (from gemini)\n","  Downloading bx_python-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from gemini) (2.0.3)\n","Collecting openpyxl<2.0.0,>=1.6.1 (from gemini)\n","  Downloading openpyxl-1.8.6-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gemini) (1.11.4)\n","Collecting Unidecode>=0.04.14 (from gemini)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cyordereddict==0.2.2 (from gemini)\n","  Downloading cyordereddict-0.2.2.tar.gz (128 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bcolz>=0.11.3 (from gemini)\n","  Downloading bcolz-1.2.1.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numexpr>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from gemini) (2.10.1)\n","Collecting coloredlogs (from cyvcf2>=0.7.2->gemini)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cyvcf2>=0.7.2->gemini) (8.1.7)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (4.4.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (0.4)\n","Requirement already satisfied: ipykernel>=4.4 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (5.5.6)\n","Requirement already satisfied: ipython>=4 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (7.34.0)\n","Requirement already satisfied: jupyter-client>=5 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (6.1.12)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (5.9.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (2.8.2)\n","Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (24.0.1)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (6.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (4.66.4)\n","Requirement already satisfied: traitlets>=4.3 in /usr/local/lib/python3.10/dist-packages (from ipyparallel>=4.0->gemini) (5.7.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython-cluster-helper>=0.5.1->gemini) (67.7.2)\n","Collecting ipython>=4 (from ipyparallel>=4.0->gemini)\n","  Downloading ipython-5.10.0-py3-none-any.whl (760 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.3/760.3 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting netifaces>=0.10.3 (from ipython-cluster-helper>=0.5.1->gemini)\n","  Downloading netifaces-0.11.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from ipython-cluster-helper>=0.5.1->gemini) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7.1->gemini) (2.1.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.11.0->gemini) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.11.0->gemini) (2024.1)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1->gemini) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1->gemini) (3.0.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.4->ipyparallel>=4.0->gemini) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4->ipyparallel>=4.0->gemini) (0.7.5)\n","Collecting simplegeneric>0.8 (from ipython>=4->ipyparallel>=4.0->gemini)\n","  Downloading simplegeneric-0.8.1.zip (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting prompt-toolkit<2.0.0,>=1.0.4 (from ipython>=4->ipyparallel>=4.0->gemini)\n","  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.4/245.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygments<2.6 (from ipython>=4->ipyparallel>=4.0->gemini)\n","  Downloading Pygments-2.5.2-py2.py3-none-any.whl (896 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m896.1/896.1 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from ipython>=4->ipyparallel>=4.0->gemini) (4.9.0)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=5->ipyparallel>=4.0->gemini) (5.7.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->cyvcf2>=0.7.2->gemini)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=5->ipyparallel>=4.0->gemini) (4.2.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4->ipyparallel>=4.0->gemini) (0.2.13)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect->ipython>=4->ipyparallel>=4.0->gemini) (0.7.0)\n","Building wheels for collected packages: gemini, cyordereddict, bcolz, geneimpacts, inheritance, ipython-cluster-helper, pybedtools, netifaces, simplegeneric\n","  Building wheel for gemini (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gemini: filename=gemini-0.30.2-py3-none-any.whl size=350609 sha256=090c470a634065cf6767b7636422e5f89d68397d942992ad5b86bb22c21bd635\n","  Stored in directory: /root/.cache/pip/wheels/c3/d6/8c/9f363a0e76af644dbaaae68228b8719aef34e0997ed79908da\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for cyordereddict (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for cyordereddict\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for cyordereddict\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for bcolz (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for bcolz\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for bcolz\n","  Building wheel for geneimpacts (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for geneimpacts: filename=geneimpacts-0.3.7-py3-none-any.whl size=41626 sha256=c08be993876e6a99978df236f368c5400a0d2a0adae010ded379244d6e863f30\n","  Stored in directory: /root/.cache/pip/wheels/1f/2e/aa/3c4a046a886593c34438876bbcd118ed3ddafd4cc3f3e9e7a5\n","  Building wheel for inheritance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for inheritance: filename=inheritance-0.1.5-py3-none-any.whl size=29101 sha256=5d1f4aa5bbe41c398175d78fd1d152d07ed2811d891991492a3d30f62af791f5\n","  Stored in directory: /root/.cache/pip/wheels/d9/2d/28/6db2a2a25d06931683861736ebf3212e13aab5c517047dcc01\n","  Building wheel for ipython-cluster-helper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipython-cluster-helper: filename=ipython_cluster_helper-0.6.4-py2.py3-none-any.whl size=18912 sha256=1d1639882a2df4a7973935f6226c0c244a0b9389ef5ace341b49d7c1fd8d961e\n","  Stored in directory: /root/.cache/pip/wheels/56/c8/8d/ce9ed75917c9b276493a54057cca5f4ae0ef09e8b47eb7e787\n","  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pybedtools: filename=pybedtools-0.10.0-cp310-cp310-linux_x86_64.whl size=14164822 sha256=b7e0d805c2aa022ab0cd4933dfd81271b3caedab2742fe428d82b89a0412552d\n","  Stored in directory: /root/.cache/pip/wheels/e5/26/a4/6913af11fdcfbc926c98fee0768b4fe955f6e3cc7ebe2c9d9e\n","  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=35008 sha256=ec91bc3a86c0760f453fa462ad55dccf93bdcc5fdd1279f4e970c0bc4fa3bd6d\n","  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n","  Building wheel for simplegeneric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simplegeneric: filename=simplegeneric-0.8.1-py3-none-any.whl size=5060 sha256=73ace019d9cab1a04d10c5036642b9735107f870e600467db2e03a7771609545\n","  Stored in directory: /root/.cache/pip/wheels/6a/88/e8/d4f4d830f0edaf91815bd9714e65b3c57ebc95c4ddfc6416a6\n","Successfully built gemini geneimpacts inheritance ipython-cluster-helper pybedtools netifaces simplegeneric\n","Failed to build cyordereddict bcolz\n","\u001b[31mERROR: Could not build wheels for cyordereddict, bcolz, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from gemini import Gemini\n","\n","cookies = {\n","    \"__Secure-1PSIDCC\" : \"AKEyXzXDs747XzAum0oMfxW1XgnFN1F4X_12NBkWWhyunhalIu7B2zk3uQ9ZILUbccQly4T2tCw\",\n","    \"__Secure-1PSID\" : \"g.a000kwhXHhqbAOj-A0qkZaWpf3z1XrpCU7aUFdzEmu1T7ZHOBSjM8X7byfvq_e8NFVvqNGK2XQACgYKAbcSARISFQHGX2MiSPLEGezheDTygkOYdydMhxoVAUF8yKo2c8otjcaRpyDMX7N6faev0076\",\n","    \"__Secure-1PSIDTS\" : \"sidts-CjEB4E2dkQUdblP4QiA154MyJP1SpBtcW_tWdrU149jyRxq1_5mba6NLgIITtZ15Y0WfEAA\",\n","    \"NID\" : \"sidts-CjEB4E2dkQUdblP4QiA154MyJP1SpBtcW_tWdrU149jyRxq1_5mba6NLgIITtZ15Y0WfEAA\",\n","    # Cookies may vary by account or region. Consider sending the entire cookie file.\n","  }\n","\n","client = Gemini(cookies=cookies)"],"metadata":{"id":"9Ba0QgWb9OMd","executionInfo":{"status":"ok","timestamp":1720369057548,"user_tz":-330,"elapsed":719,"user":{"displayName":"sanjivani sharma","userId":"08343980027590609131"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["**Simplest Chatbot**"],"metadata":{"id":"SfOoh9OM6X01"}},{"cell_type":"code","source":["prompt = \"Tell me about Large Language Model.\"\n","response = client.generate_content(prompt)\n","print(response.payload)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sar5tPJR9Moz","executionInfo":{"status":"ok","timestamp":1720369265926,"user_tz":-330,"elapsed":7117,"user":{"displayName":"sanjivani sharma","userId":"08343980027590609131"}},"outputId":"24882559-142a-45c7-8003-61a801735a8c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["{'metadata': ['c_09efd069c8ac794d', 'r_70ea13bb86d28f9e'], 'prompt_class': None, 'prompt_candidates': [], 'candidates': [{'rcid': 'rc_40ff8c67b43f220a', 'text': \"Large language models (LLMs) are essentially computer programs that are really good at understanding and using human language. They are a type of artificial intelligence (AI) program that's been trained on massive amounts of text data. This data can come from books, articles, websites, code, and even social media conversations. By analyzing all this information, LLMs learn the patterns of human language and how words are used and connected.\\n\\nHere's a breakdown of how LLMs work:\\n\\n* **Deep learning:** LLMs are built on a type of machine learning called deep learning, which uses artificial neural networks. These networks are inspired by the structure and function of the human brain.\\n* **Transformer architecture:** Many LLMs are based on a specific kind of neural network architecture called a transformer. Transformers are particularly good at understanding relationships between words in a sequence, which is essential for natural language processing.\\n* **Training data:** The key to an LLM's success is the data it's trained on. The more data, the better the LLM will be at understanding complex language.\\n\\nSo, what can LLMs do? LLMs are capable of a variety of tasks, including:\\n\\n* **Generating text:** LLMs can be used to create different kinds of creative text formats,  like poems, code, scripts, musical pieces, email, letters, etc. \\n* **Translation:** LLMs can translate languages, and can even translate between multiple languages at once.\\n* **Writing different kinds of content:**  They can be used to write different kinds of content, like blog posts, articles, news reports, etc.\\n* **Answering your questions:** LLMs can be used to answer your questions in an informative way, even if they are open ended, challenging, or strange.\\n\\nHowever, it's important to remember that LLMs are still under development. They can sometimes generate incorrect or nonsensical outputs, and they may not always be able to understand the nuances of human language. But, as LLMs continue to develop, they have the potential to revolutionize the way we interact with computers and the world around us.\", 'code': {}, 'web_images': [], 'generated_images': []}, {'rcid': 'rc_96d464d47049b2ee', 'text': \"Large language models (LLMs) are essentially computer programs that are really good at understanding and producing human language.  Here's a breakdown of how they work:\\n\\n* **Deep learning models:** LLMs are a kind of artificial intelligence (AI) program that uses deep learning techniques.  This means they are based on complex algorithms inspired by the structure and function of the human brain.\\n* **Trained on massive amounts of data:**  The secret sauce behind LLMs is the massive amount of data they are trained on. This data can include text from books, articles, code, and even conversations. By analyzing all this data, LLMs become familiar with the patterns of human language.\\n* **Transformer architecture:** Many LLMs are built using a specific kind of neural network called a transformer.  Transformers are adept at handling sequences of data, which makes them well-suited for tasks that involve understanding language.\\n\\nSo, what can LLMs actually do? Here are a few examples:\\n\\n* **Generate text:** LLMs can be used to create different creative text formats,  like poems, code, scripts, musical pieces, email, letters, etc. \\n* **Translation:** LLMs can translate languages by understanding the meaning of a sentence in one language and then generating an equivalent sentence in another language.\\n* **Question answering:** LLMs can be used to answer your questions in an informative way, even if they are open ended, challenging, or strange.\\n\\nOverall, LLMs are a powerful tool with a wide range of potential applications.  As they continue to develop, we can expect to see them used in even more innovative ways.\", 'code': {}, 'web_images': [], 'generated_images': []}, {'rcid': 'rc_1467aa3914e333e2', 'text': \"Large language models (LLMs) are essentially computer programs that are really good at understanding and using human language.  They are a type of artificial intelligence (AI) program that's been trained on massive amounts of data  -  we're talking  thousands or even millions of gigabytes of text and code. This data can come from all sorts of places, like books, articles, code repositories, and even the internet.\\n\\nHere's how it works: LLMs use a kind of machine learning called deep learning, specifically a type of neural network called a transformer model. By analyzing all this data, the model learns to recognize patterns in language, including things like grammar, syntax, and even how words are used in different contexts. This allows them to do a whole bunch of cool things, like:\\n\\n* Generate text, like poems, code, scripts, musical pieces, email, letters, etc.\\n* Translate languages\\n* Write different kinds of creative content\\n* Answer your questions in an informative way\\n\\nLLMs are still under development, but they're already being used for a variety of purposes. For example, they can be used to create chatbots that can have more natural conversations with people, or to develop new machine translation tools.\\n\\nHere are some things to keep in mind about LLMs:\\n\\n* They are not sentient or conscious. They can't think for themselves or understand the world in the same way that a human can.\\n* They can be biased, depending on the data they're trained on.\\n* They can't always tell the difference between fact and fiction. \\n\\nOverall, LLMs are a powerful new tool that has the potential to revolutionize the way we interact with computers. As they continue to develop, it will be interesting to see how they are used to shape the future.\", 'code': {}, 'web_images': [], 'generated_images': []}]}\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"mVv3cZxE7vRS"}},{"cell_type":"code","source":["input_text = 'Why is the sky blue?'"],"metadata":{"id":"OD1zt-Kt6ur0","executionInfo":{"status":"ok","timestamp":1720367965869,"user_tz":-330,"elapsed":529,"user":{"displayName":"sanjivani sharma","userId":"08343980027590609131"}}},"execution_count":13,"outputs":[]}]}